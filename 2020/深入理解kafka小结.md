
## 本节大纲
* [一、kafka基本概念](#1)
* [二、生产者](#2)
* [三、消费者](#3)
* [四、主题与分区](#4)
* [五、日志存储](#5)
* [六、可靠性方案](#6)
* [七、常见问题](#7)


## 前言
对于普通研发人员，我们只需要知道消息发送到哪个Topic，从哪个Topic 订阅消息就可以。但如果了解了kafka内部的一些细节，则可以让我们扬长补短，为排查问题提供思路，进而更好的使用kafka。

## <span id="1">一、kafka基本概念</span>

### 1.1 kafka特点(优点)
 kafka是分布式的基于发布、订阅的消息系统。有以下特点：
* 快速数据持久化，基于时间轮(Timing Wheel底层数组)插入和删除实现了O(1)时间复杂度
* 高吞吐：能在普通的单机服务器上达到10W每秒的吞吐速率，甚至100w+(消息字节小10k左右)
* 高可靠：消息持久化、副本、事务、幂等机制保证了消息的可靠性(高可用) 
* 高扩展：Broker、Producer和Consumer都原生自动支持分布式，自动实现负载均衡

**缺点：**
* 单机kafka如果分区过大(>64)，load会高，负载高，相应时间长
* 轮询方式，实时性取决于时间间隔
### 1.2 kafka的角色
* 消息系统(消息中间件)：应用解耦、流量消峰、异步处理、冗余存储、异步通信
* 存储系统：持久化磁盘(数据保留策略设置为"永久")及多副本机制，日志存储
* 流式处理平台：为流式处理提供可靠的数据来源和完整的流式处理类库。例如：用户浏览商品行为记录，先浏览A，再浏览B，与流式处理对应的是批处理(对汇总的用户行为进行处理，延时容忍度高)
### 1.3 kafka常用的应用场景
* 应用解耦：业务解耦
* 流量消峰：用于抢购和秒杀场景
* 异步处理：串行请求通过kafka异步处理转为并行请求
* 冗余存储：多副本机制实现了故障自动转移和冗余存储，提供数据的可靠性
* 日志存储：大量日志存储，单磁盘io受限 

### 1.4 kafka体系结构
体系机构：
* Producer:生产者，生产消息的一方
* Consumer:消费者，接收消息的一方
* Broker:服务代理节点，通常情况下，一个kafka实例就是一个broker，多个实例构成集群。
另外其它概念：
* 主题：消息以主题归类
* 分区：从存储层面看作可追加的日志文件，每追加一次产生特定offset,在分区内唯一且有序，同一个主题的不同分区可以分布在不同的服务器(broker)上,增加分区数量实现了水平扩展。
* 多副本：实现了故障自动转移和冗余存储。leader和follower副本,前者负责对外读写请求，后者负责同步信息
## <span id="2">二、生产者</span>

### 2.1 生产流程
  消息在通过send()发往broker的过程中，有可能需要经过拦截器(Interceptor)、序列化器(Serializer)和分区器(Partitioner)的一系列作用之后才能被真正地发往broker。
* 拦截器：非必须，对于生产者端对于消息发送前或者发送回调做一些定制化的需求
* 序列化器：必须的，与消费者反序列化器对应
* 分区器：为消息分配分区，没有指定partition字段，需要分区器。如果key不为空，默认分区器对key哈希，对哈希值计算分区号，如果key为null，则以轮询的方式发送到分区。也可以自定义分区器。

### 2.2 生产者客户端整体架构
* 两个线程，主线程和发送线程(Sender),前者将消息通过拦截器、序列化器、分区器，然后缓存到消息累加器(RecordAccumulator)。后者负责从消息累加器消息发送到kafka
* 主线程中发送过来的消息先放在BufferPool，都会被追加到消息累加器的某个双端队列(Deque)中，消息追加到列尾，sender线程从列头批量获取消息。
* sender线程发送到kafka之前还会保存在InFlightRequests中，作用是缓存了已经发出去但还没有收到响应的请求，如果堆积很多未响应的，说明这个node负载较大火灾网络连接有问题，再发送会超时。
## <span id="3">三、消费者</span>
### 3.1 消费者和消费组
* 每个消费者都对应一个消费组，当消息发布到主题后，只会被订阅他的消费组中的一个消费组消费
* 消费组模式让整体的消费能力横向伸缩，增加(减少)消费者的个数，可以提高(降低)整体的消费能力
### 3.2 消息流程
**大概流程：**订阅主题--反序列化--消费消息--位移提交--拦截器--多线程实现
* 消费消息：基于pull拉取
* 位移提交：消费消息与位移提交的顺序不同，出现丢失和重复消费问题；将pull消息放在db 或者redis中，消费后，再手动提交位移；指定位移消费(lastest\earliest)
* 拦截器：在消费消息或者提交位移做一些定制化的操作
* 多线程实现：基于滑动窗口，分阶段提交
* 分组协调者：存储消费组相关的元数据，包括 分区、主题、broker
* 重平衡：新消费者、消费者下线、分区发送变化


## <span id="4">四、主题与分区</span>
   从kafka底层实现来说，主题和分区都是逻辑上概念。主题作为消息的分类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。分区的划分不仅为kafka提供了可伸缩性、水平扩展的功能，还通过多副本机制实现了故障自动转移和数据冗余存储，提供了数据可靠性。

* 分区可以有一个至多个副本，每个副本对应一个日志（Log）文件，每一个日志文件对应一个至多个日志分段(LogSegment)，日志分段可以细分为日志文件和索引文件组成(偏移量和时间戳),相当于将巨型文件平均分配到小文件。
* 分区删除：
  - 基于时间删除：消息在集群保留时间超过设定阈值，log.retention.hours，默认为168小时，即七天
  - 基于空间删除：超过 log.segment.bytes 1G
  - 基于日志起始偏移量删除：通常<起始偏移量logStartOffset

#### 4.2.1 分区的管理
* 优先副本的选举:在AR集合列表中的第一个副本，执行选举脚步避开业务高峰期
* 分区重分配：将分区副本再次合理的均衡分配。场景：broker下线，需要将副本转移到其它broker;新增broker需要与之前broker重新分配
* 复制限流：重分配本质是数据复制，先增加新副本，然后数据同步到副本，最后删除就副本。数据复制会占用资源，限流机制保证重分配期间服务不受影响。
* 修改副本因子：修改副本个数
* 分区分配策略：
   - 默认 RangeAssignor:按照消费者总数和分区总数进行整除得到跨度，然后将分区按照跨度进行平均分配，不均匀的放在前面消费者
   - RoundRobinAssignor:主题分区按照字典排序，然后通过轮询方式逐个将分区依次分配给消费者
   - StickyAssignor:该分配方式在0.11版本开始引入，主要是保证以下特性：1.尽可能的保证分配均衡；2.当重新分配时，保留尽可能多的现有分配。其中第一条的优先级要大于第二条


#### 4.2.2 如何选择合适的分区？ 分区数越多吞吐量越高吗？
* 吞吐量：理论上分区越多，吞吐量越大，但吞吐量还会受磁盘、文件系统、iO调度策略相关，吞吐量太大在多副本同步性能下降，leader副本的切换会耗时
* 结合业务场景：有些场景要求主题中的消息都能有序，这种情况下可以设置分区为1或者多分区使用根据业务使用相同key，将相关业务放在一个分区中
* 通常设置分区数量为broker的倍数，如果3个broker,则分区设置为 6，12

## <span id="5">五、日志存储</span>
### 5.1 文件目录布局
  主题--分区log--日志分段logSegment--索引文件/数据文件(磁盘)
### 5.2 磁盘存储
* 操作系统对线性读写做了优化，磁盘预读(预先将磁盘块读入到内存)和后写(将小的逻辑写合并起来组成大的物理写)
* 顺序写盘方式：kafka采用文件追加方式来写入消息
* 页缓存：是操作系统实现的一种磁盘缓存，为了减少磁盘IO的操作。具体做法将磁盘数据缓存到内存中，对磁盘的访问变为对内存的访问。读文件先读缓存其次磁盘；写文件先写缓存(脏页)
* 零拷贝：数据直接从磁盘文件复制到网卡设备中(socket)，减少了内核与用户模式的切换
## <span id="6">六、可靠性方案</span>
### 6.1 概括
kafka使用多副本机制，实现水平扩展、提供了容灾能力、提升可用性和可靠性。对此我们也引申了一部分问题：多副本之间如何进行数据同步？同步发生异常如何处理？多副本一致性怎样解决？一致性协议是啥?消息可靠性如何保持等。带着这些问题看一下kafka是如何解决的
### 6.2 副本剖析
* 副本是分布式系统中常见的概念之一，是分布式系统对数据和服务提供的一种冗余方式。分两种数据副本和服务副本。
   - 数据副本：指不同节点上持久化同一份数据，当某个节点上存储的数据丢失时，可以从副本上读取数据，这是解决分布式系统数据丢失问题最有效的手段
   - 服务副本：多个节点提供同样的服务，每个节点都有能力接收外部请求并进行相应的处理。
* AR=ISR+OSR，Assigned Replicas 分区中所有副本称为AR。副本必须满足两个条件：
  - 必须与zk保持心跳
  - follower最后偏移量与leader偏移量不能超过系统阈值
* ISR:In-Sync Replicas 所有与leader副本保持一定程度同步的副本，包含leader副本，ISR是AR副本的一个子集。消息先写入leader副本，然后follower副本才能才leader副本中拉取消息进行同步，同步有一定程度滞后，滞后范围参数配置。ISR的引入主要是有效权衡了数据的可靠性和性能之间的关系，解决同步副本与异步复制两种方案各自的缺陷（同步副本中如果有个副本宕机或者超时就会拖慢该副本组的整体性能；如果使用异步副本，当所有的副本消息均远落后于主副本时，一旦主副本宕机重新选举，那么就会存在消息丢失情。
* OSR:Out-of-sync Replicas，与leader副本滞后过多的副本。
* HW&LEO:HW俗称高水位线，消费者只能拉取到HW之前的消息；LEO标识每个分区最后一条消息的下一个位置，分区的每个副本都有自己的LEO
* HW截断机制：leader宕机了，其它follwer和之前leader回复过来需要与新选举的leaderHW保持一致，需要截断自己的
* Reblance：当集群中的某个节点出现故障，访问故障节点的请求会被转移到其他正常节点(这一过程通常叫 Reblance)。
* 遇到问题：数据不一致和数据丢失场景(以下案例前提：min.insync.replicas=1，意味着只要主副本成功写入了消息,就认为这条消息已经提交了)
  - 正常情况：B为主副本，有两条消息，A为follower副本，同步B,此时A、B都为LEO都为2，HW都为1，此时A再向B拉消息，FetchRequest请求中带上了自己的LEO信息，B收到信息之后更新了自己的HW为2，B没有更多消息，但因为延时队列，会晚一点返回FetchResponse，并在其中包括HW消息；最后A根据FetchResponse中的HW信息更新了自己的HW为2。总结三点(1.先更新LEO,次轮才能更新HW,2.leader和follower副本HW更新有间隙，3.follower副本的HW不能比leader副本的HW高)
  - 数据丢失：主副本A HW=2,LEO=2,副本B获取A,更新了自身的LEO=2，但HW需要次轮才能更新为2，此时B宕机了，B重启后HW仍然为1，此时A宕机了，B被选为leader，则之前获取A并更新LEO对应的消息丢失了
  - 数据不一致：主副本A HW=2,LEO=2，Bfollower副本HW和LEO都为1，此时A\B同时宕机，B先恢复过来成为leader，并写入新消息m,更新自己 HW=2 ，LEO=2。此时A恢复获取，拉取数据发现没有获取到新数据。虽然两者HW和LEO都相同，但A中没有消息m,造成消息不一致
* 解决方案：Kafka（0.11.0.0）引入了leader epoch，在需要截断数据的时候使用leader epoch作为参考依据而不是原本的。eader epoch表示一个键值对<epoch, offset>，其中epoch表示leader主副本的版本号，从0开始编码，当leader每变更一次就会+1，offset表示该epoch版本的主副本写入第一条消息的位置。
比如<0,0>表示第一个主副本从位移0开始写入消息，

### 6.4 kafka 为什么不像mysql、redis支持读写分离？

* 读写分离(主写从读)明显的缺点：
   - 数据的不一致：因为数据从主节点到从节点必然存在一个延时的时间窗口
   - 延时问题：例如 redis 需要经过网络--主内存--网络--从内存，整个过程会耗时，而kafka需要经过 网络--leader内存--磁盘--网络--从节点内存--磁盘 链路较长，kafka不采用这种

* kakfa 通过多分区和多副本机制实现负载均衡，但有些情况下负载不均衡，比如：
  - 分区数量：解决方式通过在主题创建时尽可能预估分区的数量
  - 写入消息不均或者消费消息不均 这个读写分离也解决不了
  - leader副本的切换：解决方式提供有效副本选举，结合监控、告警、运维平台实现均衡的优化
* kafak:只支持主写主读优点如下：
  - 简化代码的实现逻辑，减少出错的可能
  - 将负载粒度细化分摊，与主写从读相比，负载更好，对用户可控(指定分区)
  - 副本稳定的情况下，不会出现数据不一致的情况

### 6.5 kafka 日志同步机制(协议)？
   在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。最简单高效的方式在集群中选出一个leader来负责处理数据写入的顺序，只有leader处于存活状态，那么follower只需按照leader中的写入顺序进行同步即可。

* 基本原则：只要告诉客户端消息已提交，那么即使宕机，也要保证新选举leader中包含这条消息。
* 同步机制使用ISR模型，而不是采用少数服从多数的模式
   - 少数服从多数优势在于系统的延迟取决于最快的几个节点，但劣势是如果要容忍1个节点失败，则至少需要3个节点，如果容忍2个节点失败，则至少5个节点，需要节点数量多，那么同步的时候性能就会下降
   - ISR模型：写入leader后，保证ISR中所有副本都确认收到了，则认为已提交；leader选举优先选择AR中的第一个存活副本(结合配置参数unclean.leader.election.enable=true/false)

### 6.6 可靠性级别
在生产者向kafka集群发送时，数据经过网络传输，也是不可靠的，可能因为网络延迟、闪断等原因造成数据的丢失。
  kafka为生产者提供了如下的三种可靠性级别，通过不同策略保证不同的可靠性保障。其实此策略配置的就是leader将成功接收消息信息响应给客户端的时机。

   **通过request.required.acks参数配置：**

* 1：生产者发送数据给leader，leader收到数据后发送成功信息，生产者收到后认为发送数据成功，如果一直收不到成功消息，则生产者认为发送数据失败会自动重发数据。 当leader宕机时，可能丢失数据。

* 0：生产者不停向leader发送数据，而不需要leader反馈成功消息。
   这种模式效率最高，可靠性最低。可能在发送过程中丢失数据，也可能在leader宕机时丢失数据。

* -1：生产者发送数据给leader，leader收到数据后要等到ISR列表中的所有副本都同步数据完成后，才向生产者发送成功消息，如果一只收不到成功消息，则认为发送数据失败会自动重发数据。
    这种模式下可靠性很高，但是当ISR列表中只剩下leader时，当leader宕机让然有可能丢数据。

### 6.7 leader选举
   当leader宕机时会选择ISR中的一个follower成为新的leader，如果ISR中的所有副本都宕机，怎么办？

   有如下配置可以解决此问题：

    unclean.leader.election.enable=false

  *  策略1：必须等待ISR列表中的副本活过来才选择其成为leader继续工作。可靠性有保证，但是可用性低，只有最后挂了leader活过来kafka才能恢复

    unclean.leader.election.enable=true

  * 策略2：允许从非ISR中选择一个活过来的副本，成为leader继续工作，从AR中找到第一个存活的副本
   可用性高，可靠性没有保证，任何一个副本活过来就可以继续工作，但是有可能存在数据不一致的情况。


### 6.8 kafka可靠性的保证
一般而言，消息中间件的消息传输保障有3个层级：
* At most once：至多一次，消息可能会丢，但绝不会重复传输。(拉取到消息先提交位移后处理消息，遇到宕机的情况下)
* At least once：最少一次，消息绝不会丢，但可能会重复传输。(拉取到消息，先处理消息后提交位移，遇到宕机的情况下)
* Exactly once：恰好一次，每条消息肯定会被传输一次且仅传输一次。
  kafka从0.11.0.0版本开始引入幂等和事务两个特性，实现 excatly once，
  **幂等** 
  为了实现生产者的幂等，kafka引入producer_id简称PID和序列号sequence number，broker端会在内存中为每一对<PID，分区>维护一个序列号。SN_new=SN_old+1broker会正确接收，小于说明重复写入，大于有数据没有写入，存在数据丢失。
   幂等的关键在于服务端能否识别出请求是否重复，然后过滤掉这些重复请求，通常情况下需要以下信息来实现幂等特性：
  - 唯一的标识：判断请求是否充分，需要唯一的标识
  - 记录已处理过的请求：根据唯一标识记录以处理请求，进行去重判断
使用幂等的前提：单个生产对话中单个分区幂等，对于多分区情况需要使用事务，如果做到全局的幂等，需要上下游综合考虑，通常做法订单ID作为唯一标识，下游做去重表。

**事务**
幂等性并不能跨分区操作，而事务可以保证对多个分区写入操作，要么全部成功，要么全部失败。
kafka中的事务可以使用消费消息、生产消息、提交位移当作原子操作来处理，同时成功或失败。
## <span id="7">七、常见问题</span>
### 7.1 kafka如何实现高并发存储？如何找到一条需要消费的数据?

**kafka存储机制：**
* 主题与分区：kafka消息以主题为单位进行归类，生产者负责将消息发到特定主题，主题是一个逻辑上概念，它可以细分到多个分区，分区在存储层面可以看作一个可追加的日志Log文件，如果一个主题只有一个分区的话，机器的IO是个瓶颈，影响主题性能。所以一个主题会有多个分区，分布在不同broker上，通过增加分区的数量，可以实现分区的水平扩展
* 分区多副本机制：kafka为分区引入多副本(Replica)机制,通过增加副本数量，提供了故障的自动转移和容灾能力，当集群中某个broker失效时仍然能保证服务可用，提示可用性和可靠性
* 分区存储索引文件：分区文件存储多个logSegment日志片段，每个日志片段包括 .index、.timestamp和.log文件，分别对应偏移量和时间戳的索引文件和数据文件。索引文件存在于内存中，为了提高查询效率。
  - 偏移量的索引文件：建立了消息偏移量offset到物理地址之间的映射关系，方便快速定位消息数据所在的物理文件的位置
  - 时间戳的索引文件：根据指定时间戳timestamp来查找对应偏移量信息

**kafka可靠性：** 详见（上面的第六部分、可靠性方案）
* 可靠性机制，采用多副本机制：
* 可靠性级别：acks=-1
* 可靠性保证：at least once
**kafka查找消费的数据：**
* 第一步：二分查找，找索引文件：根据偏移量offset查找偏移量索引文件或者根据时间戳查找时间索引文件，如果找不到则返回小于指定偏移量的最大偏移量。如果找到了索引文件
* 第二步：根据稀疏索引找到索引对应的物理文件的地址，即数据文件.log,类似于mysql非聚集索引的回表查询，
kafka用了稀疏索引的方式，使用了二分查找法。稀疏索引节省了空间，但增加了查找的时间，它在磁盘空间、内存空间、查找时间等方面做了tradeoff折中。
比如：查找 offset=123111 message消息，分两步：
* 1.二分查找logSegment 的偏移量索引文件
* 2.根据偏移量索引文件查找物理文件地址.log

ps:联想到mysql Innodb索引
主键索引(聚簇索引): 叶子节点存的是整行数据,属于密集索引
非主键索引(二级索引): 叶子节点内容是索引值主键的值,属于稀疏索引

### 7.2 与传统的消息系统相比，Kafka 的消费模型有什么优点?
 消息的消费一般有两种模式：推Push模式和拉Poll模式
* 传统消息系统:推拉结合
* kafka:通过poll拉模式，原因如下：
  - 如果使用push推送模式：如果push成功，但消息进程挂掉或者网络中断，造成消息丢失，如果要生产者记录消息状态，这种方式实现成本大；如果push速度比消费速度快，造成堵塞。
  - 使用poll,可用消费者自己控制消费进度和速度，也可以指定偏移量进行消费(在新的消费组或者新主题情况下，找不到消费组所记录的消费偏移量)
  - 黑盒使用poll(),其内部逻辑并不简单，涉及消息位移，消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡逻辑及心跳，详见（上面的第三部分、消费者）


### 7.3 Kafka 为什么比 RocketMQ 支持的单机 Partition 要少?

### 消息中间件kafka面试题
#### Kafka讲一讲？原理？
kafka是一个分布式的、分区的、多副本的、多订阅者的分布式消息队列。消费队列作用：削峰、解耦。支持点对点、发布/订阅。
包括：生产者、broker、消费者。

#### Kafka如何解决数据堆积
分析堆积原因，如果有错误解决错误，没有错误考虑是否增加新的消费者
#### kafka消息的存储机制
主题、分区、副本、日志log、日志片段logSegment
### 如何用kafka保证消息的有序性
* 生产者：因为单个分区内是有序的，所以生产者只要将消息发往一个分区就可以。要么指定分区，要么使用相同key,分区器会自动将消息发往同一个分区
* 消费者：如果是单个消费者从单分区中消费必然是有序的。但这种消费吞吐能力弱。所以通常使用多线程模式 即多个消费者。我们将生产者的消息根据相同的key分到10个队列中，然后开启10个consumer消费对应的队列。
### kafka如何保证并发情况下消息只被消费一次
幂等性：单分区下，保证生产者写入消息只会存储一条信息
事务:保证跨生产者会话的消息幂等发送
#### 如何保证消息不丢失？
多副本min.insync.replicas>1;acks=-1必须保证所有副本都接收；
#### 消息队列的优缺点，区别
* 优点：解耦、异步、削峰
* 缺点：系统可用性降低，多了mq，mq挂了怎么办？系统复杂的提高了，需要保证消息丢失、重复消费问题、系统不一致问题
#### kafka 和rabbtMQ比较：
name | 确认机制 |  消息顺序| 吞吐量|使用场景|  
-|-|-|-|-|
kafka | 无确认 | 在一个分区内是有序的，整体是无序 |10w+|吞吐量大、大量计算、日志采集、运维系统监控|
rabbtMQ | 生产者confirm机制以及消费者的消息应答机制ack |一个队列里面严格顺序 |10w+|金融场景对可靠性要求高|

#### 消息中间件的高可用
kafka 多分区 多副本：一个broker挂了，还有其他副本，
发送acks确认：leader和follower副本都存在数据
leader选举：如果leader挂了，follower选举新的leader

#### 如何保证消息不被重复消费
消费端需要处理，常见解决方案：redis set去重；db 去重表；生产者写入唯一标识，消费者根据唯一标识去重
#### 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时呢？
通常一个消费者1s消费1000条，有3个消费者的话，1s消费3000条，1h消费18w条。几百万条的话，处理流程如下，实际临时扩容，10倍的速度并发消费
* 1.消费consumer的bug，并停止 
* 2.新增topic, 分区是原来10倍，为了保证顺序，根据相同key 放在队列中
* 3.新增10倍consumer，一起并发消费
#### 如果让你写一个消息队列，该如何进行架构设计？
参考kafka架构
* 自动扩容： broker -> topic -> partition
* 消息持久化：生产端写入消息的逻辑：主线程和sender线程，最终写入磁盘
* 消息的可靠性：多分区多副本机制
* 消息消费的高效：稀疏索引，二分查找消息数据


#### 通过kafka将mysql binlog 同步到es
mysql同步es有两种方法，一通过阿里云DTS；二通过订阅binlog，使用go-mysql-elasticsearch 开源库，主要说一下第二种重要点：
* 1.订阅binlog，将binlog需要信息，发送kafka，下游系统各取所需
* 2.保证kafka顺序性和完整性：
  - 顺序性：每条 binlog 使用 Primary Key，Hash 到各个 Partition 上，保证相同Primary key的数据都发送到同一个 Partition
  - 完整性：成功es后再进行kafka offset位移提交
* 3.日志监控：对每一条记录都有日志，遇到问题及时报警


#### Kafka是如何实现高吞吐率的
* 页缓存：是操作系统实现的一种主要的磁盘缓存，以此来减少对磁盘io的操作
* 顺序读写：kafka的消息是不断追加到文件中的，磁盘顺序读写比随机读写快
* 零拷贝：减少内核和用户模式切换，直接将磁盘文件复制到网卡设备(socket buffer)
* 文件分段：一个topic被分为了多个分区partition，每个分区partition又分为多个段log segment，所以一个队列中的消息实际上是保存在N多个片段文件中
* 批量发送：Kafka允许进行批量发送消息，发送前在消息累计器的在内存中，然后一次请求批量发送出去
* 数据压缩：Kafka还支持对消息集合进行压缩

> reference
《深入理解Kafka核心设计与实践原理》
